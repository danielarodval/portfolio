{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0Flyu1932QQ"
   },
   "source": [
    "# Daniel Rodriguez: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ybGKx57Pk1m"
   },
   "source": [
    "# A5 Convolutional Neural Network (Total 150pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVP7tS--i3RX"
   },
   "source": [
    "## 1. Import libraries (Total 6pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u58q6TY6ZIog"
   },
   "source": [
    "### 1.1 Import torch, torchvision, torchvision.transforms, torch.utils.data and torch.nn (6pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5PQaDXCRZILB"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as tr\n",
    "from torch.utils import data\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPlUbT1LUOXw"
   },
   "source": [
    "## 2. Data Preparation (Total 32pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aJns258Ygtk"
   },
   "source": [
    "### 2.1 Image Transformation (12pts)\n",
    "Define a transformation pipeline using torchvision.transforms.Compose.\n",
    "\n",
    "In the pipeline, use **ColorJitter, GaussianBlur, RandomHorizontalFlip, ToTensor and Normalize** from the transforms library.\n",
    "\n",
    "For the first four transformations, use suitable parameters of your informed choice. At the end, normalize the images with mean 0.5 and variance 0.5.\n",
    "\n",
    "Read about these transformations here: https://pytorch.org/vision/0.9/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3L1sTEpVY-Ks"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "transform_pipeline = tr.Compose([\n",
    "  tr.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "  tr.GaussianBlur(kernel_size=(3,3), sigma=(0.5,2.0)),\n",
    "  tr.RandomHorizontalFlip(p=0.5),\n",
    "  tr.ToTensor(),\n",
    "  tr.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdjyzDc-ZViW"
   },
   "source": [
    "### 2.2 Prepare train and test set by loading CIFAR10 dataset from torchvision.datasets. (4pts)\n",
    "Make sure you are using the **transform** pipeline (you just wrote in task #2.1) on both train and test set. \n",
    "\n",
    "**Hint:** Preparing train and test sets can be directly achieved by utilizing the class parameters.\n",
    "\n",
    "\n",
    "Read about CIFAR10 dataset class in PyTorch: https://pytorch.org/vision/0.9/datasets.html#cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLPlRVeuPcqG",
    "outputId": "2d223519-fb10-470a-a574-6e6727be8caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_pipeline)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fv4E4y4EWVY"
   },
   "source": [
    "### 2.3 Use torch.utils.data.random_split() to make a validation set from the training set with 80:20 split. (3pts)\n",
    "\n",
    "Make sure the training set you'll use after this point excludes the validation set of images \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5xcbx036EV0B"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "num_train_samples = int(len(train_set) * 0.8)\n",
    "num_val_samples = len(train_set) - num_train_samples\n",
    "\n",
    "train_set, val_set = data.random_split(train_set, [num_train_samples, num_val_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdARFhumrvz3"
   },
   "source": [
    "### 2.4 Prepare three dataloaders for train, validation and test set. Use an appropriate batchsize of your choice. (1+2+2+2 =7pts)\n",
    "\n",
    "\n",
    "**Hints:**\n",
    "1. Remember that choosing a batchsize is always a trade-off between efficiency and generalizability. With large batchsize, your model learns more and better in each forward pass, but each pass will require larger computation. On the other hand, with small batchsize, it might converge quicker, but each forward pass teaches features from a smaller subset, which may not be a good representation of the overall data; leading to jittery convergence.\n",
    "2. During training, you will use the train and validation set for tracking the loss and avoiding overfitting. The test set will be hold out until you are ready to evaluate a trained model on new data. \n",
    "\n",
    "Read about pytorch Dataloaders here:\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XNi2NNQ2rhEp"
   },
   "outputs": [],
   "source": [
    "# TODO: set a batch size\n",
    "batch_size = 64\n",
    "\n",
    "# TODO: write dataloader for train set\n",
    "train_loader = data.DataLoader(train_set, batch_size=batch_size)\n",
    "\n",
    "# TODO: write dataloader for test set\n",
    "test_loader = data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# TODO: write dataloader for validation set\n",
    "val_loader = data.DataLoader(val_set, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fso-pay0yLOF"
   },
   "source": [
    "### 2.5 Load a random batch of images from the training set using the trainloader. Then use *make_grid()*  from *torchvision.utils* and *imshow()* from *matplotlib.pyplot* to show the images. Also, print the corresponding true labels for those image samples. (6pts)\n",
    "Hint: you may need to reshape the *make_grid()* output to comply with the format *imshow()* accepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "b-uAZo9Ui8rA",
    "outputId": "ff0c2c2f-9fb8-4c72-dabf-aa1d4c5ee444"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "# TODO: load a random batch of test set images\n",
    "data_iterator = iter(train_loader)\n",
    "images, labels = next(data_iterator)\n",
    "grid = make_grid(images, nrow=8, padding=2)\n",
    "grid = grid.numpy().transpose((1,2,0))\n",
    "\n",
    "# TODO: show the images\n",
    "plt.imshow(grid)\n",
    "plt.show()\n",
    "\n",
    "# TODO: print the ground truth class labels for these images\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print('True labels:', ' '.join(classes[labels[j]] for j in range(batch_size)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BGKE4TkUR2q"
   },
   "source": [
    "## 3. Model Design (Total 22pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT4AFLfO0iQi"
   },
   "source": [
    "### 3.1 Define a neural network model: (2+7+7 =16pts)\n",
    "- Name the model class with your first name\n",
    "- In the following sequential order, the model should consist:\n",
    "\n",
    "    (1) a 2D convolution layer with 6 filters, dimension of each filter is (5, 5), stride=1, no zero padding\n",
    "    \n",
    "    (2) a Max Pool layer with filter size (2, 2), stride=2\n",
    "    \n",
    "    (3) a 2D convolution layer with 16 filters, dimension of each filter is (5, 5), stride=1, no zero padding\n",
    "\n",
    "    (4) a 2D Max Pool layer with filter size (2, 2), stride=2\n",
    "    \n",
    "    ~ a flatten layer ~\n",
    "\n",
    "    (5) a Dense/Fully-connected layer with 120 neurons\n",
    "    \n",
    "    ~ a ReLU activation ~\n",
    "    \n",
    "    ~ a Dropout Layer ~\n",
    "\n",
    "    (6) a Dense/Fully-connected layer with 80 neurons\n",
    "    \n",
    "    ~ a ReLU activation ~\n",
    "\n",
    "    (7) a Dense/Fully-connected layer with 10 neurons\n",
    "\n",
    "Note: \n",
    "1. Flatten, ReLU and Dropout are not really \"layers\". They are operations with specific purpose. But in model construction in pytorch, they are abstracted as layers.\n",
    "    \n",
    "    Flatten is used to convert the 4th layer output to a 1D tensor so that it can be passed through the next fully-connected layer. Since each forward pass takes a batch of data, use the *start_dim* parameter of *torch.flatten()* appropriately to keep the batch dimension intact.\n",
    "    \n",
    "    ReLU is an activation that transforms the Dense Layer's linear output to a non-linear \"active\" output.\n",
    "    \n",
    "    Dropout is a regularization technique. Read more in slides. In this assignment, you can drop neurons with 50% probability. \n",
    "\n",
    "2. This dataset has 10 classes, hence the final layer consists 10 neurons. \n",
    "\n",
    "3. The model architecture is similar to the one you saw in in-class Quiz 2, with an extra dense layer in the end. \n",
    "\n",
    "    Read about building your custom model in pytorch here: https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html\n",
    "\n",
    "    The official pytorch documentation on conv, flatten, rely, dense are also resourceful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "825WS6h7UQx4"
   },
   "outputs": [],
   "source": [
    "class Daniel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # TODO: Initialize the layers\n",
    "        super(Daniel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1 , padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1 , padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(120,80)\n",
    "        self.fc3 = nn.Linear(80, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Define the dataflow through the layers\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x =  self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikcGyq4q6UHV"
   },
   "source": [
    "### 3.2 Create an instance of the model class that you just prepared. (2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1rdVDhTUk2J"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "model = Daniel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xr5Nkses6boD"
   },
   "source": [
    "### 3.3 Set up Cross Entropy Loss as the loss function and *Adam* as the optimizer. Use a learning rate of your choice for the optimizer. (4pts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuJa233WUmE-"
   },
   "outputs": [],
   "source": [
    "# TODO: Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1gE9KU6UYEg"
   },
   "source": [
    "## 4. Training and Validation (Total 50pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPyjTxYmB3mR"
   },
   "source": [
    "### 4.1 Write a training loop to load data, compute model output, compute loss and backpropagating it to update model parameters. (30pts)\n",
    "\n",
    "The # TODO tags below contain further instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRQ6CRuLUpaD",
    "outputId": "76d2534f-6f3a-4c59-c1e4-5cae09bad4af"
   },
   "outputs": [],
   "source": [
    "# TODO: Define number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# TODO: Initialize empty lists to store training loss, training accuracy, validation loss, validation accuracy \n",
    "# You will use these lists to plot the loss history.\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "# TODO: Loop through the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # TODO: set model to train mode\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # TODO: iterate over the training data in batches\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        # TODO: get the image inputs and labels from current batch\n",
    "        # done at the for loop\n",
    "        \n",
    "        # TODO: set the optimizer gradients to zero to avoid accumulation of gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: compute the output of the model\n",
    "        outputs = model(images)\n",
    "\n",
    "        # TODO: compute the loss on current batch\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # TODO: backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # TODO: update the optimizer parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # TODO: update the train loss and accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # TODO: compute the average training loss and accuracy and store in respective arrays\n",
    "    train_loss_history.append(running_loss / len(train_set))\n",
    "    train_acc_history.append(running_corrects.double() / len(train_set))\n",
    "\n",
    "    # TODO: set the model to evaluation mode\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "\n",
    "    # TODO: keeping the gradient computation turned off, loop over batches of data from validation set.\n",
    "    with torch.no_grad():\n",
    "      for val_images, val_labels in val_loader: \n",
    "            # TODO: compute output of the model\n",
    "            val_outputs = model(val_images)\n",
    "\n",
    "            # TODO: compute the loss\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            \n",
    "            # TODO: compute the validation loss and accuracy\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "            \n",
    "            val_running_loss += val_loss.item() * val_images.size(0)\n",
    "            val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
    "\n",
    "    # TODO: compute the average validation loss and accuracy and store in respective lists\n",
    "    val_loss_history.append(val_running_loss / len(val_set))\n",
    "    val_acc_history.append(val_running_corrects.double() / len(val_set))\n",
    "\n",
    "    # TODO: print the training loss, training accuracy, validation loss and validation accuracy at the end of each epoch\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}: '\n",
    "          f'Train Loss: {(running_loss / len(train_set)):.4f}, Train Accuracy: {(running_corrects.double() / len(train_set))}, '\n",
    "          f'Validation Loss: {(val_running_loss / len(val_set)):.4f}, Validation Accuracy: {(val_running_corrects.double() / len(val_set)):.4f}')\n",
    "\n",
    "    # TODO: save the model parameters once in every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "      torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fHqWfUu38c9"
   },
   "source": [
    "### 4.2 Plot and compare (5+5 =10pts)\n",
    "1. training and validation loss over the number of epochs\n",
    "2. training and validation accuracy over the number of epochs\n",
    "\n",
    "(Hint: Use plot() from *matplotlib.pyplot*, import it if you haven't already done so.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "v1-ES2jFXUkO",
    "outputId": "eca0dbe2-e50b-441e-b488-132d3832094d"
   },
   "outputs": [],
   "source": [
    "# TODO: plot the training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), train_loss_history, label='Training Loss')\n",
    "plt.plot(range(num_epochs), val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "# TODO: plot the training and validation accuracy\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), train_acc_history, label='Training Accuracy')\n",
    "plt.plot(range(num_epochs), val_acc_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9QZka69C21Z"
   },
   "source": [
    "### 4.3 Discussion: (2*5 = 10pts)\n",
    "(1) Does the training loss and accuracy improve as number of epoch increases?\n",
    "\n",
    "(2) Does the validation loss and accuracy improve as number of epoch increases?\n",
    "\n",
    "(3) Are there any sign of overfitting in the results? If so, when did it start to occur?\n",
    "\n",
    "(4) How many epochs did it take for the model to converge to a good solution?\n",
    "\n",
    "(5) What enhancement can be tried to the architecture to further improve the validation performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_EdvCc6D_p9"
   },
   "source": [
    "~ # TODO\n",
    "\n",
    "(1) Yes, the training loss and accuracy improve as the number of epochs increases.\n",
    "\n",
    "(2) Yes, the validation loss and accuracy improve as the number of epochs increases.\n",
    "\n",
    "(3) No, there are no clear indicators of overfitting since the training loss/accuracy are not inversely related to the validation loss/accuracy. They both increase and decrease at relatively the same rates.\n",
    "\n",
    "(4) The model plateaued/converged around epoch 16, though there were still improvements with epoch 20.\n",
    "\n",
    "(5) Increasing the depth of the model by adding more layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P68A6mXEUcp0"
   },
   "source": [
    "## 5. Testing on new data (Total 40pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xvVXl19VaP2"
   },
   "source": [
    "### 5.1 Load the best performing model (one with good validation accuracy and without overfitting) among the ones you saved. (4pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIKphuXBVgKe",
    "outputId": "ad66669d-4d77-41d5-ff80-95491722c31a"
   },
   "outputs": [],
   "source": [
    "# TODO: instantiate a model\n",
    "model = Daniel()\n",
    "\n",
    "# TODO: load parameters from one of the saved model states\n",
    "model.load_state_dict(torch.load('model_epoch_15.pth'))\n",
    "\n",
    "# TODO: set this model to evaluation mode \n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yx7EXuj3EnC9"
   },
   "source": [
    "### 5.2 Take a random batch of images from test set and show the images. Print the corresponding ground truth class labels. Then compute model output (model selected at previous step) and the predicted labels for the images in this batch. (10pts)\n",
    "\n",
    "This is similar to task #2.5 with additional task on computing model output and printing predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "GXPZTs1vUfoG",
    "outputId": "36a8d150-320d-428f-c003-362181920798"
   },
   "outputs": [],
   "source": [
    "# TODO: load a random batch of test set images\n",
    "data_iterator = iter(test_loader)\n",
    "images, labels = next(data_iterator)\n",
    "\n",
    "# TODO: show the images\n",
    "grid = make_grid(images, nrow=8, padding=2)\n",
    "grid = grid.numpy().transpose((1,2,0))\n",
    "plt.imshow(grid)\n",
    "plt.show()\n",
    "\n",
    "# TODO: print the ground truth class labels for these images\n",
    "print([label.item() for label in labels])\n",
    "\n",
    "# TODO: compute model output\n",
    "with torch.no_grad():\n",
    "  outputs = model(images)\n",
    "\n",
    "# TODO: print the predicted class labels for these images\n",
    "_, predicted_labels = torch.max(outputs, 1)\n",
    "print([label.item() for label in predicted_labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBDJ6Sr-FQde"
   },
   "source": [
    "### 5.3 Compute the average accuracy on test data using this model. (4+2 =6pts)\n",
    "Loop over the test set, compute accuracy on each batch, lastly print the average accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0n8MHS1BK3gd",
    "outputId": "003b2291-1d63-4456-c34f-a7c4a2e92d97"
   },
   "outputs": [],
   "source": [
    "# TODO: compute accuracy on each batch of test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# TODO: print the average accuracy\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_loader:\n",
    "    outputs = model(images)\n",
    "    _, predicted_labels = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted_labels == labels).sum().item()\n",
    "\n",
    "print(f'Average accuracy on test data: {(100 * correct / total)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYWWJo7yFsxN"
   },
   "source": [
    "### 5.4 Compute the average accuracy for each individual class. (8+4 =12pts)\n",
    "Hint: similar to #5.3. During each loop, log the accuracy for each class separately (a python/numpy dictionary can help). Then print the individual accuracy for the 10 output classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AhIyXe1Rmkq",
    "outputId": "331944c5-e699-426c-a6d5-d4698658565e"
   },
   "outputs": [],
   "source": [
    "# TODO: compute per-class accuracy on each batch of test set\n",
    "class_correct = {i: 0 for i in range(10)}\n",
    "class_total = {i: 0 for i in range(10)}\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_loader:\n",
    "    outputs = model(images)\n",
    "    _, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "    correct = (predicted_labels == labels)\n",
    "\n",
    "    for i in range(labels.size(0)):\n",
    "      true_label = labels[i].item()\n",
    "      class_correct[true_label] += correct[i].item()\n",
    "      class_total[true_label] += 1\n",
    "\n",
    "print(f'Average accuracy on test data: {(100 * correct / total)}%')\n",
    "\n",
    "# TODO: print per-class accuracy for 10 output classes\n",
    "for i in range(10):\n",
    "    accuracy = 100 * class_correct[i] / class_total[i]\n",
    "    print(f'Accuracy for class {i} ({classes[i]}): {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HJVKMSUGnMW"
   },
   "source": [
    "### 5.5 Discussion: (2+2+4 =8pts)\n",
    "1. Which class of images were detected with highest accuracy? \n",
    "2. Which class of images were hardest for the model to detect? \n",
    "3. Explain 1-2 possible reasons why detection of some class can be harder for the same model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYdbEUN_G00t"
   },
   "source": [
    "~ # TODO\n",
    "\n",
    "(1) Class 9, truck, had the highest accuracy.\n",
    "\n",
    "(2) Class 1 and 8, car and boat, had the lowest accuracy.\n",
    "\n",
    "(3) This could be due to high intra-class variation within the images of the same class being very different from each other. Or, inter-class similarity where images from different classes look very similar to each other."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
