{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb79759",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:3rem;color:orange;\">Homework 5</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b6264a",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf9b69",
   "metadata": {},
   "source": [
    "### Problem 1 In this problem you will compare the performance of a variety of classifiers that you have learned about so far. The data is in the file magic04.data and the column names are in the file magic04.names. The last column is a categorical response with values g or h, and the rest of the columns are numerical features. You can read more about the dataset here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc384137",
   "metadata": {},
   "source": [
    "#### (a) Load the data (can use the pandas function read table with the arguments sep=’,’ and header=None). Split the data into a training and test set. Scale and center the columns using the mean and standard deviation of each column from the training set (make sure you use the same scaling on the test set that is used on the training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e382c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
      "\n",
      "    fAlpha     fDist class  \n",
      "0  40.0920   81.8828     g  \n",
      "1   6.3609  205.2610     g  \n",
      "2  76.9600  256.7880     g  \n",
      "3  10.4490  116.7370     g  \n",
      "4   4.6480  356.4620     g  \n"
     ]
    }
   ],
   "source": [
    "#%% Step 1- imports data into dataframe\n",
    "import pandas as pa;\n",
    "import timeit;\n",
    "\n",
    "col_names=['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
    "df = pa.read_table('C:/Users/danma/Downloads/magic04.data', sep=',', header=None, names=col_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb8fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Size =  0.25 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%% Step 2 - splits data into x and y\n",
    "\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "\n",
    "x = df.filter(regex='f')\n",
    "y = df.filter(regex='class')\n",
    "#repace categorical data characters with 1 and 0, 1 to separate from 0\n",
    "y = y.replace('g',1, regex=True)\n",
    "y = y.replace('h',0, regex=True)\n",
    "#turns y into a 1-d array instead of a dataframe column\n",
    "y = y.to_numpy()\n",
    "y = y.ravel()\n",
    "y = y.astype('int')\n",
    "\n",
    "#splits into training and test data\n",
    "TS = 0.25 #for tuning\n",
    "print(\"Test Size = \", TS, \"\\n\")\n",
    "x_train, x_test, y_train, y_test = TTS(x,y,test_size=TS, random_state=42)\n",
    "\n",
    "del df, col_names, TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "599c07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Step 3 - scale and center columns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(x_train)\n",
    "\n",
    "x_train = scalar.transform(x_train)\n",
    "x_test = scalar.transform(x_test)\n",
    "\n",
    "del scalar\n",
    "\n",
    "#To tune hyperparameters for each model, you can either use cross-validation or hand-tune by examining\n",
    "#the model performance for reasonable values of the hyper-parameters.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Apply your models to the test set. Report the accuracy, visualize an ROC curve, and report the AUC\n",
    "#for each model. For Logistic Regression, Random Forests, and Gradient Boosted Decision Trees, report\n",
    "#the most meaningful predictors.\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d333c608",
   "metadata": {},
   "source": [
    "#### (b) Learn the following models to classify the training data: <br>• Logistic Regression: Can import LogisticRegression from sklearn.linear model.<br>• LDA: Can import LinearDiscriminantAnalysis from sklearn.discriminant analysis.<br>• KNN Classifier: Need to choose the number of neighbors k.<br>• Linear SVM: Need to choose the margin penalty C as a hyperparameter.<br>• Gaussian (Radial) SVM: Need to choose the margin penalty C and the radius width γ.<br><br>To tune hyperparameters for each model, you can either use cross-validation or hand-tune by examining the model performance for reasonable values of the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4fbc82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "Best penalty: l1\n",
      "Best C: 1000.0\n",
      "Best multi_class: auto\n",
      "Best solver: liblinear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Step 4 - Logistic Regression\n",
    "print(\"Logistic Regression Results:\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "#%% Step 4.1 Tuning Hyperparameters - Did not provide change in accuracy nor auc\n",
    "\n",
    "# parameter grid\n",
    "parameters = {\n",
    "    'penalty' : ['l1','l2'], \n",
    "    'C'       : np.logspace(-3,3,10),\n",
    "    'solver'  : ['liblinear', 'saga']\n",
    "}\n",
    "#Create new reg object\n",
    "logregtest = LogisticRegression(max_iter=5000)\n",
    "#use gridsearch\n",
    "grid = GridSearchCV(logregtest, param_grid = parameters, cv=10, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "best_logreg = grid.fit(x, y)\n",
    "\n",
    "print('Best penalty:', best_logreg.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_logreg.best_estimator_.get_params()['C'])\n",
    "print('Best multi_class:', best_logreg.best_estimator_.get_params()['multi_class'])\n",
    "print('Best solver:', best_logreg.best_estimator_.get_params()['solver'])\n",
    "\n",
    "#fit the model\n",
    "logreg = LogisticRegression(penalty=best_logreg.best_estimator_.get_params()['penalty'], \n",
    "                            C=best_logreg.best_estimator_.get_params()['C'], \n",
    "                            multi_class=best_logreg.best_estimator_.get_params()['multi_class'],\n",
    "                           solver=best_logreg.best_estimator_.get_params()['solver'])\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e70c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant Analysis Results:\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Best solver: svd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Step 5 - LDA\n",
    "print(\"Linear Discriminant Analysis Results:\")\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "#%% Step 5.1 Tune Hyperparameters for LDA\n",
    "parameters = {\n",
    "    'solver'  : ['svd', 'lsqr', 'eigen']  \n",
    "}\n",
    "#Create new reg object\n",
    "ldatest = LinearDiscriminantAnalysis()\n",
    "#use gridsearch\n",
    "grid = GridSearchCV(ldatest, param_grid = parameters, cv=10, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "best_lda = grid.fit(x, y)\n",
    "\n",
    "print('Best solver:', best_lda.best_estimator_.get_params()['solver'])\n",
    "\n",
    "#%%\n",
    "#fit the model\n",
    "lda = LinearDiscriminantAnalysis(solver=best_lda.best_estimator_.get_params()['solver'])\n",
    "lda.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa359cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Results:\n",
      "Fitting 10 folds for each of 2842 candidates, totalling 28420 fits\n",
      "Best n_neighbors: 12\n",
      "Best leaf_size: 1\n",
      "Best p: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(leaf_size=1, n_neighbors=12, p=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Step 6 - KNN Classifier\n",
    "print(\"KNN Classifier Results:\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#%% Step 6.1 Tune Hyperparameters for KNN\n",
    "parameters = {\n",
    "    'n_neighbors'  : list(range(1,30)),\n",
    "    'leaf_size' : list(range(1,50)),\n",
    "    'p' : [1,2]\n",
    "}\n",
    "#Create new reg object\n",
    "knntest = KNeighborsClassifier()\n",
    "#use gridsearch\n",
    "grid = GridSearchCV(knntest, param_grid = parameters, cv=10, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "best_knn = grid.fit(x, y)\n",
    "\n",
    "print('Best n_neighbors:', best_knn.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best leaf_size:', best_knn.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_knn.best_estimator_.get_params()['p'])\n",
    "\n",
    "#fit the model\n",
    "neigh = KNeighborsClassifier(n_neighbors=best_knn.best_estimator_.get_params()['n_neighbors'],\n",
    "                            leaf_size=best_knn.best_estimator_.get_params()['leaf_size'],\n",
    "                            p=best_knn.best_estimator_.get_params()['p'])\n",
    "neigh.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be4490",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Results:\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "#%% Step 7 - Linear SVM\n",
    "print(\"Linear SVM Results:\")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Step 7.1 - Tune Hyperparameters for Linear SVM\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "             } \n",
    "\n",
    "#Need to choose the margin penalty C as a hyperparameter\n",
    "#Create new reg object\n",
    "lsvmtest = SVC(kernel='linear')\n",
    "#use gridsearch\n",
    "grid = GridSearchCV(lsvmtest, param_grid = parameters, cv=10, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "best_lsvm = grid.fit(x, y)\n",
    "\n",
    "print('Best C:', best_lsvm.best_estimator_.get_params()['C'])\n",
    "\n",
    "#fit the model\n",
    "lin_svm = SVC(C=best_lsvm.best_estimator_.get_params()['C'],\n",
    "              kernel='linear')\n",
    "lin_svm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Step 8 - Gaussian SVM\n",
    "print(\"Gaussian SVM Results:\")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Step 8.1 - Tune Hyperparameters for Gaussian SVM\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "             } \n",
    "\n",
    "#Need to choose the margin penalty C and the radius width γ.\n",
    "#Create new reg object\n",
    "gsvmtest = SVC(kernel='rbf')\n",
    "#use gridsearch\n",
    "grid = GridSearchCV(gsvmtest, param_grid = parameters, cv=10, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "best_gsvm = grid.fit(x, y)\n",
    "\n",
    "print('Best C:', best_gsvm.best_estimator_.get_params()['C'])\n",
    "print('Best gamma:', best_gsvm.best_estimator_.get_params()['gamma'])\n",
    "\n",
    "\n",
    "#fit the model\n",
    "gau_svm = SVC(kernel='rbf',\n",
    "              C = best_gsvm.best_estimator_.get_params()['C']\n",
    "              gamma = best_gsvm.best_estimator_.get_params()['gamma'])\n",
    "gau_svm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33037fe",
   "metadata": {},
   "source": [
    "#### (c) Apply your models to the test set. Report the accuracy, visualize an ROC curve, and report the AUC for each model. For Logistic Regression, report the most meaningful predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4aef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression Results:\")\n",
    "# predict probabilities\n",
    "logreg_pred = logreg.predict_proba(x_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "logreg_pred = logreg_pred[:, 1]\n",
    "\n",
    "#print accuracy of the model\n",
    "print(\"Accuracy: %.3f\" %logreg.score(x_test, y_test))\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg_pred)\n",
    "pyplot.plot(fpr, tpr, marker='.', label='Logistic Regression ROC')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, logreg_pred)\n",
    "print('AUC: %.3f\\n' % auc)\n",
    "\n",
    "del logreg_pred, fpr, tpr, thresholds, auc\n",
    "\n",
    "print(\"Linear Discriminant Analysis Results:\")\n",
    "#predict probabilities\n",
    "lda_pred = lda.predict_proba(x_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lda_pred = lda_pred[:, 1]\n",
    "#print accuracy of the model\n",
    "print(\"Accuracy: %.3f\" %lda.score(x_test, y_test))\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lda_pred)\n",
    "pyplot.plot(fpr, tpr, marker='.', label='LDA ROC')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, lda_pred)\n",
    "print('AUC: %.3f\\n' % auc)\n",
    "\n",
    "del lda_pred, fpr, tpr, thresholds, auc\n",
    "\n",
    "print(\"KNN Classifier Results:\")\n",
    "#predict probabilities\n",
    "neigh_pred = neigh.predict_proba(x_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "neigh_pred = neigh_pred[:, 1]\n",
    "#print accuracy of the model\n",
    "print(\"Accuracy: %.3f\" %neigh.score(x_test, y_test))\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, neigh_pred)\n",
    "pyplot.plot(fpr, tpr, marker='.', label='KNN ROC')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, neigh_pred)\n",
    "print('AUC: %.3f\\n' % auc)\n",
    "\n",
    "#Need to choose the number of neighbors k\n",
    "del neigh_pred, fpr, tpr, thresholds, auc\n",
    "\n",
    "print(\"Linear SVM Results:\")\n",
    "#predict probabilities\n",
    "lin_svm_y_pred = lin_svm.predict(x_test)\n",
    "\n",
    "#print accuracy of the model\n",
    "print(\"Accuracy: %0.3f\" %lin_svm.score(x_test, y_test))\n",
    "\n",
    "#roc curve\n",
    "svc_disp = RocCurveDisplay.from_predictions(y_test, lin_svm_y_pred, name=\"Linear SVM ROC\")\n",
    "pyplot.show()\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#auc score\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, lin_svm_y_pred)\n",
    "score = metrics.auc(fpr, tpr)\n",
    "print(\"AUC: %0.3f \\n\" %score)\n",
    "\n",
    "del lin_svm_y_pred, svc_disp, fpr, tpr, threshold\n",
    "\n",
    "print(\"Gaussian SVM Results:\")\n",
    "#predict probabilities\n",
    "gau_svm_y_pred = gau_svm.predict(x_test)\n",
    "\n",
    "#print accuracy of the model\n",
    "print(\"Accuracy: %0.3f\" %gau_svm.score(x_test, y_test))\n",
    "\n",
    "#roc curve\n",
    "svc_disp = RocCurveDisplay.from_predictions(y_test, gau_svm_y_pred, name=\"Gaussian SVM ROC\")\n",
    "pyplot.show()\n",
    "\n",
    "#auc score\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, gau_svm_y_pred)\n",
    "score = metrics.roc_auc_score(y_test, gau_svm_y_pred)\n",
    "print(\"AUC: %0.3f \\n\" %score)\n",
    "\n",
    "del gau_svm_y_pred, score, svc_disp, fpr, tpr, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Importance\n",
    "importance = logreg.coef_[0]\n",
    "\n",
    "colnames = list(x_train.columns)\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint(colnames[i],'Score: %.5f' % (abs((v))))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], abs(importance))\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
