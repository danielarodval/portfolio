{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea7d190",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:3rem;color:orange;\">Final Exam</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b64787b",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c5222d",
   "metadata": {},
   "source": [
    "#### (50 points) This problem will examine the data set online_shoppers_intention.csv Download online_shoppers_intention.csv. Each row gives a variety of information about a single individual’s online habits. Information about the features in this dataset can be found here Links to an external site.. We are interested in the Revenue response, which is a binary variable indicating whether an individual made a purchase while browsing. This dataset features class imbalance, so we will investigate some tools for dealing with this. Code related to oversampling and Precision-Recall curves for unbalanced data can be found here class_imbalance_example.Rmd Download class_imbalance_example.Rmd.  Analyze this dataset by following the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1900665",
   "metadata": {},
   "source": [
    "#### (a)  Load the data. Make sure categorical variables are formatted correctly. Merge rare categories for categorical features (40 or fewer observation) into a single feature. Split the data into a train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f1ee9",
   "metadata": {},
   "source": [
    "#### (b)  The response in this dataset provides an example of class imbalance. In particular, the proportion of shopppers who do make a purchase is much smaller than the proportion of shoppers who do not make a purchase. Models might not learn anything in this case, because high accuracy can be achieved by always predicting the majority class. To deal with class imbalance, you can oversample the minority class, which involves sampling rows of the minority class with replacement. From your training dataset only (not the validation dataset), create a new training dataset by oversampling the minority class so there are an equal number of responses in both categories. You will use this training dataset when learning your model. You should use the original validation set when evaluating your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c62172",
   "metadata": {},
   "source": [
    "#### (c)  Use the training data to create 2 different models to predict Revenue given all other features: an LDA model, and a QDA model. Your models can use all features as predictors, for this problem you don’t have to investigate feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d605975",
   "metadata": {},
   "source": [
    "#### (d)  Using the validation data, make an ROC curve for each model and calculate the AUC for the ROC curves. Comment on the differences that you observe between the different methods. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
